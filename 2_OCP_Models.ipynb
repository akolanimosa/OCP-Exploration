{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29c7a83a-edea-41eb-b299-0a1e14852427",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "\n",
    "1. [Overview of Baseline OC20 Models](#1)\n",
    "    1. [Graph Neural Networks(GNNs)](#1.1)\n",
    "        1. [Resources for GNN Study](#1.1.1)\n",
    "        2. [Graphs](#1.1.2)\n",
    "        3. [Graph Attributes](#1.1.3)\n",
    "        3. [Basics of GNNs](#1.1.4)\n",
    "        3. [Message Passing in Detail](#1.1.5)\n",
    "    2. [Crystal Graph Convolutional Neural Networks (CGCNNs) and OCP](#1.2)\n",
    "        1. [General Mechanism](#1.2.1)\n",
    "        2. [Convolution Layers](#1.2.2)\n",
    "        2. [Pooling Layer](#1.2.3)\n",
    "        2. [Hidden Layers](#1.2.4)\n",
    "    3. [Using OCP Models](#1.3)\n",
    "        1. [Preparing Config Files](#1.3.1)\n",
    "        2. [Training Models](#1.3.2)\n",
    "        3. [Making Predictions](#1.3.3)\n",
    "        4. [Single Value Predictions](#1.3.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c48142b-c977-4a3d-b5a9-34656db1fa01",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"1\"></a>\n",
    "# Overview of Baseline OC20 Models\n",
    "\n",
    "There are multiple baseline models provided by OCP, every one of them being a graph-neural-network(GNN). In this section, we will first inspect some basics of GNNs, then models provided by OCP to understand the current state of model development."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1765f7a4-77d7-44bd-89c8-9d5ce7176158",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "## Graph Neural Networks(GNNs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a199e48-da0b-4ed4-877a-affe231fc934",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"1.1.1\"></a>\n",
    "#### *Resources for GNN Study*\n",
    "\n",
    "First, I will provide a few resources if you wish to study the topic broadly:\n",
    "- A very useful on-purpuse book called Graph Representation Learning by William L. Hamilton from McGill University that can be accessed freely and legally from [this link](https://www.cs.mcgill.ca/~wlh/grl_book/files/GRL_Book.pdf).\n",
    "- A modern web-article for introduction to Graph Neural Networks on [distill.pub](https://distill.pub/) that can be accessed [here](https://distill.pub/2021/gnn-intro/).\n",
    "- Video lectures of CS224W provided by Stanford Online. This is a very in-depth, and great course for formally studying the subject. Here is the [link](https://www.youtube.com/playlist?list=PLoROMvodv4rPLKxIpqhjhPgdQy7imNkDn).\n",
    "- Practical and short videos that are great to skim through the topic on YouTube. Can be accessed [here](https://www.youtube.com/playlist?list=PLV8yxwGOxvvoNkzPfCx2i8an--Tkt7O8Z).\n",
    "- Hands-on PyTorch Geometric tutorials on Youtube. Can be accessed [here](https://www.youtube.com/playlist?list=PLGMXrbDNfqTzqxB1IGgimuhtfAhGd8lHF).\n",
    "- [Review Paper by Zhou et al.](https://arxiv.org/pdf/1812.08434.pdf)\n",
    "\n",
    "I will briefly explain the GNNs and their natural connection to our topic. Yet, I reccomend you at least check the basic information covered in the materials above if wish to familiarize yourself with the subject."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491d56d8-d629-47b5-aac0-f3893f25603e",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"1.1.2\"></a>\n",
    "#### *Graphs*\n",
    "\n",
    "Graphs are abstract mathematical structures that are a constructed from nodes and edges. \n",
    "\n",
    "<img src=\"./Figures/fig_graph.png\" width=200>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254f010b-595a-4922-98fa-eba062d2bf52",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"1.1.3\"></a>\n",
    "#### *Graph Attributes*\n",
    "\n",
    "We can store information in nodes, edges and globally. It can be practical to think of this information as attribute vectors of the regarding element. We can store multiple attributes in one node or vertex. \n",
    "\n",
    "For example, if we try to model a molecule, we can store the atom properties in the node attributes and bond properties in the vertex attributes, while the molecular properties are the global attributes.\n",
    "\n",
    "<img src=\"./Figures/fig_graphmolecule.png\" width=200>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0314dc5e-73eb-46d9-99a7-8adc903a55f8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "<a class=\"anchor\" id=\"1.1.4\"></a>\n",
    "#### *Basics of GNNs*\n",
    "Graph neural networks are the type of neural networks that operate on graphs. They embreace the principle \"graph in - graph out\". They are intutively apropriate for our tasks since atoms and interactions establish a natural analogy to nodes and edges as seen in the above example. \n",
    "\n",
    "The basic mechanism can be explanined as follows: \n",
    "1. We input a graph.\n",
    "2. From our input, an embedding for each node and edge is created from their attributes. The size of the embedding list is a hyperparameter.\n",
    "<center><b>Message Passing(Repeated for each hidden layer)</b></center>\n",
    "<hr>\n",
    "\n",
    "1. For each node in the graph, gather all the neighboring node embeddings (or messages).\n",
    "\n",
    "2. Aggregate all messages via an aggregate function (like sum).\n",
    "\n",
    "3. All pooled messages are passed through an update function, usually a learned neural network.\n",
    "\n",
    "<hr>\n",
    "\n",
    "5. Predictions are made using the final embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200c76ac-d867-433d-9179-64613ac0a2d1",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"1.1.5\"></a>\n",
    "#### *Message Passing in Detail*\n",
    "\n",
    "Message passing is the process of nodes transferring information between one and another naturally. For n message passing layers, the output node embedding will contain the contributions of its n'th neighbor. The core process of iteration is given below.\n",
    "\n",
    "Process is described in the below color coded figures:\n",
    "\n",
    "<table><tr>\n",
    "<td> <img src=\"./Figures/fig_messagepassing.jpg\" width=400> </td>\n",
    "<td> <img src=\"./Figures/fig_messagepassing2.jpg\" width=400> </td>\n",
    "</tr></table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdad6422-5632-478c-9429-081894951d33",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"1.2\"></a>\n",
    "## Crystal Graph Convolutional Neural Networks (CGCNNs) and OCP\n",
    "\n",
    "There are a very large variety of GNN structures used in OCP for different tasks (CGCNN, SchNet, DIMENET, GemNet, etc.). Their configs are accessible through the [repository](https://github.com/Open-Catalyst-Project/ocp/tree/main) and even some pretrained models are avaliable. For the sake of briefness and readibility, we will only discuss the most basic one, CGCNN. This section aims to provide the reader an insight of what is going on by skiming through one example. Please see the links below for all the models and configs provided by OCP.\n",
    "- [Pretrained model list and their performances](https://github.com/Open-Catalyst-Project/ocp/blob/main/MODELS.md)\n",
    "- [Config Files](https://github.com/Open-Catalyst-Project/ocp/tree/main/configs)\n",
    "- [Models](https://github.com/Open-Catalyst-Project/ocp/tree/main/ocpmodels/models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07fdf9c-1901-42ec-9861-b7266036d485",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"1.2.1\"></a>\n",
    "#### *General Mechanism*\n",
    "\n",
    "You can access the git repository of CGCNN via [this link](https://github.com/txie-93/cgcnn).\n",
    "\n",
    "CGCNN can be described in two parts with four steps:\n",
    "<center><b>A. Crystal to Graph</b></center>\n",
    "<hr>\n",
    "\n",
    "1. Representing the crystal structure as a graph with nodes as atoms and edges as atomic interactions, respectively.\n",
    "\n",
    "<center><b>B. Graph to Target</b></center>\n",
    "<hr>\n",
    "\n",
    "2. Using R number of convolution layers to learn features from neighboring atoms.\n",
    "3. Using a pooling layer to concentrate all information into a single feature vector.\n",
    "4. Using an output layer to predict target property.\n",
    "\n",
    "The figure below provides a description of the process.\n",
    "\n",
    "<img src=\"./Figures/fig_cgcnn.jpg\" width=300>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92a117d-9d7c-40fd-b700-725ce7393274",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"1.2.2\"></a>\n",
    "#### *Convolution Layers*\n",
    "\n",
    "Convolution is the process of learning from neighboring nodes. We described almost the same mechanism used here above in the Message Passing section. Simply, we iteratively aggregate the embeddings in neighboring atoms and update the embeddings in our node. For each iteration(each convolution layer), information from the next neighbor will be learned. By doing so, each node will become a representation of its local environment. Convolution layers are put in use to do just that.\n",
    "\n",
    "$v_i^{(t+1)} = Con(v_i^{(t)}, v_j^{(t)}, u_{(i, j)k})$,  $(i, j) \\in G $ -> $v$ is the feature vector."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0390a3a-b4b4-4274-acc2-4d3d1a317c9b",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"1.2.3\"></a>\n",
    "#### *Pooling Layer*\n",
    "\n",
    "Pooling is the operation we will use to generate an overall feature vector for the whole crystal. We take all of the atom feature vectors(convulated vectors in our case), and then concentrate them into a matrix. Then, we combine them in a specific way using a defined or learned function like normalized summation or a multilayer perceptron. An example visualization is given below.\n",
    "\n",
    "<img src=\"./Figures/fig_pool.jpg\" width=300>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254fd9cb-8e22-45b4-aab4-c23b4279d874",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"1.2.4\"></a>\n",
    "#### *Hidden Layers*\n",
    "\n",
    "In addition to convolution and pooling layers, there are also two fully-connected hidden layers with the depth of $L_1$ and $L_2$ is used to capture the complex connections between crystal structure and property. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6dc196c-86b0-48d9-a409-03c658c6ffee",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"1.3\"></a>\n",
    "## Using OCP Models\n",
    "Here, we will inspect and use pre-trained CGCNN model. Same method is also applicable for other models.\n",
    "\n",
    "Note that I am performing everything on a M1 MacBook with macOS Ventura 13.4.1, and I can only perform computations on my CPU since there are no CUDA cores in my setup. I am hoping this will not cause any problems for you while you are running the notebook, but if a problem occurs, this is likely to be the reason. You may want to check for problems about installation and package dependencies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb459ef-ab83-40d1-88d2-f638aee5cddc",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"1.3.1\"></a>\n",
    "#### *Preparing Config Files*\n",
    "\n",
    "Before we proceed with predictions, we need to set our config files. For this example, everything is already set up but in case the reader needs further applications, it can be helpful to demonstrate the process.\n",
    "\n",
    "1. First, go to the parent directory of the config you want to work with. It is configs/s2ef/all/ for our example.\n",
    "2. Open base.yml, and set the directories for train, validation and test datasets. You may notice that they are all set to the same dataset in our config. This is done since we do not aim to get any actual results here. However, you may change them as you wish.\n",
    "3. Go to configs/s2ef/all/cgcnn and open cgcnn.yml. There are number of parameters if you require customization. I set num_workers to 0 and max_epoch to 1 to speed up the process. It is highly likely that you will need to redefine them according to your purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844b53ee-8f0a-42c7-842a-b691b69578f2",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"1.3.2\"></a>\n",
    "#### *Training Models*\n",
    "\n",
    "We will use command line interface to interact with the models as described below.\n",
    "```bash\n",
    "conda activate ocp-models # Activating the environment ocp is installed.\n",
    "\n",
    "config_path=\"./configs/s2ef/all/cgcnn/cgcnn.yml\" # Path to config.\n",
    "checkpoint_path=\"./checkpoints/cgcnn_all.pt\" # Path to checkpoint.\n",
    "\n",
    "python main.py --mode train --config-yml $config_path # Mode, config, checkpoint.\n",
    "```\n",
    "Now the training has begun. You can expect it to take quite a long time if you have limited computational power.\n",
    "\n",
    "Note: You may see the warnings \"LMDB does not contain edge index information, set otf_graph=True\" and \"Turning otf_graph=True as required attributes not present in data object\" if your dataset does not contain edge information. In our case, our dataset does not, and we will compute edge information on the run. This choice trades computation time with storage and is specifically made to reduce the dataset size."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74d7497-fe2c-45dc-86bc-3ba5de2f6344",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"1.3.3\"></a>\n",
    "#### *Making Predictions*\n",
    "\n",
    "Only difference here is that we need to pass the directory of the checkpoint we wish to use. We will use the model which is pre-trained over all training dataset. Checkpoints of pre-trained models can be downloaded from the OCP repository, or you can use the checkpoints of manually trained models.\n",
    "```bash\n",
    "conda activate ocp-models # Activating the environment ocp is installed.\n",
    "\n",
    "config_path=\"./configs/s2ef/all/cgcnn/cgcnn.yml\" # Path to config.\n",
    "checkpoint_path=\"./checkpoints/cgcnn_all.pt\" # Path to checkpoint.\n",
    "\n",
    "python main.py --mode predict --config-yml $config_path --checkpoint $checkpoint_path # Mode, config, checkpoint.\n",
    "\n",
    "```\n",
    "We expect to see the progess printed on the terminal, and finally the results of the prediction. \n",
    "\n",
    "Note: Above described situation about edge information is still valid. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b5fd7a-6c86-4f65-a8fa-0e5ae4ee6b13",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"1.3.4\"></a>\n",
    "#### *OCP Calculator for ASE*\n",
    "OCP also provide a calculator that can be used with ASE. After importing the calculator, you need to pass it a config and checkpoint to use. We will use, GemNet here in this example. Since checkpoint file size is too large for GitHub, you may need to download it separetely "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b4c22d9f-1ba6-4663-b8e5-944d79cefe1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amp: false\n",
      "cmd:\n",
      "  checkpoint_dir: /Users/irmakaslan/OCP/checkpoints/2023-08-08-21-33-36\n",
      "  commit: 090486f\n",
      "  identifier: ''\n",
      "  logs_dir: /Users/irmakaslan/OCP/logs/tensorboard/2023-08-08-21-33-36\n",
      "  print_every: 100\n",
      "  results_dir: /Users/irmakaslan/OCP/results/2023-08-08-21-33-36\n",
      "  seed: null\n",
      "  timestamp_id: 2023-08-08-21-33-36\n",
      "dataset: null\n",
      "gpus: 0\n",
      "logger: tensorboard\n",
      "model: gemnet_t\n",
      "model_attributes:\n",
      "  activation: silu\n",
      "  cbf:\n",
      "    name: spherical_harmonics\n",
      "  cutoff: 6.0\n",
      "  direct_forces: true\n",
      "  emb_size_atom: 512\n",
      "  emb_size_bil_trip: 64\n",
      "  emb_size_cbf: 16\n",
      "  emb_size_edge: 512\n",
      "  emb_size_rbf: 16\n",
      "  emb_size_trip: 64\n",
      "  envelope:\n",
      "    exponent: 5\n",
      "    name: polynomial\n",
      "  extensive: true\n",
      "  max_neighbors: 50\n",
      "  num_after_skip: 2\n",
      "  num_atom: 3\n",
      "  num_before_skip: 1\n",
      "  num_blocks: 3\n",
      "  num_concat: 1\n",
      "  num_radial: 128\n",
      "  num_spherical: 7\n",
      "  otf_graph: true\n",
      "  output_init: HeOrthogonal\n",
      "  rbf:\n",
      "    name: gaussian\n",
      "  regress_forces: true\n",
      "noddp: false\n",
      "optim:\n",
      "  batch_size: 32\n",
      "  clip_grad_norm: 10\n",
      "  ema_decay: 0.999\n",
      "  energy_coefficient: 1\n",
      "  eval_batch_size: 32\n",
      "  eval_every: 5000\n",
      "  factor: 0.8\n",
      "  force_coefficient: 100\n",
      "  loss_energy: mae\n",
      "  loss_force: l2mae\n",
      "  lr_initial: 0.0005\n",
      "  max_epochs: 80\n",
      "  mode: min\n",
      "  num_workers: 2\n",
      "  optimizer: AdamW\n",
      "  optimizer_params:\n",
      "    amsgrad: true\n",
      "  patience: 3\n",
      "  scheduler: ReduceLROnPlateau\n",
      "slurm: {}\n",
      "task:\n",
      "  dataset: trajectory_lmdb\n",
      "  description: Regressing to energies and forces for DFT trajectories from OCP\n",
      "  eval_on_free_atoms: true\n",
      "  grad_input: atomic forces\n",
      "  labels:\n",
      "  - potential energy\n",
      "  metric: mae\n",
      "  train_on_free_atoms: true\n",
      "  type: regression\n",
      "trainer: forces\n",
      "\n",
      "      Step     Time          Energy         fmax\n",
      "BFGS:    0 21:33:41       -0.750040        0.0144\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ocpmodels.common.relaxation.ase_utils import OCPCalculator\n",
    "from ase.optimize import BFGS\n",
    "from ase.build import fcc100\n",
    "\n",
    "checkpoint = \"checkpoints/gemnet_t_direct_h512_all.pt\"\n",
    "config = \"configs/s2ef/all/gemnet/gemnet-dT.yml\"\n",
    "\n",
    "# Construct a sample structure\n",
    "adslab = fcc100(\"Cu\", size=(3, 3, 3))\n",
    "\n",
    "adslab.center(vacuum=13.0, axis=2)\n",
    "\n",
    "# Define the calculator\n",
    "calc = OCPCalculator(checkpoint=checkpoint)\n",
    "\n",
    "# Set up the calculator\n",
    "adslab.calc = calc\n",
    "\n",
    "opt = BFGS(adslab, trajectory=\"data/toy_c3h8_relax.traj\")\n",
    "\n",
    "opt.run(fmax=0.05, steps=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ocp",
   "language": "python",
   "name": "ocp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
